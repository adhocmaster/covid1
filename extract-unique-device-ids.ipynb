{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from datetime import datetime, timedelta\n",
    "exec(open(\"./lib/splitter.py\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputDir = './data/splitted' + '/'\n",
    "outputPrefix= '_'\n",
    "inputFile = './data/Santa_Clara_County_Pin_Report_1e6.tsv'\n",
    "df = dd.read_csv(inputFile, sep='\\t')\n",
    "df = df.rename(columns=columnNamesMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cachedRows = getInitializedCacheRows(dates)\n",
    "flushSize = 10000 # write after parsing flushSize number of rows.\n",
    "progress = 0\n",
    "count = 0 # to track number of rows in cache   \n",
    "for index, row in df.iterrows():\n",
    "    if row['hid'] in cachedRows:\n",
    "        cachedRows['hid'][1] += 1\n",
    "    else:\n",
    "        progress = progress + 1\n",
    "        cachedRows['hid'] = [row['date'], 1]\n",
    "    \n",
    "    \n",
    "    if count >= flushSize:\n",
    "        flushDataToFiles(cachedRows)\n",
    "        print(f\"found {progress} unique device ids.\")\n",
    "        count = 0\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
